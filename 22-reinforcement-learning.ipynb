{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning using Q-Learning\n",
    "\n",
    "Notes: https://github.com/daviskregers/notes/blob/master/data-science/06-more-data-mining-and-machine-learning-techniques/04-reinforcement-learning.md\n",
    "\n",
    "---\n",
    "\n",
    "We want to build a self-driving taxy that can pick up passengers at one of a set of fixed locations, drop them off another and get there in the quickest amount of time while avoiding obstacles.\n",
    "\n",
    "The AI Gym lets us create this environment quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.18.0.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/davis/anaconda3/lib/python3.8/site-packages (from gym) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/davis/anaconda3/lib/python3.8/site-packages (from gym) (1.19.2)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow<=7.2.0\n",
      "  Downloading Pillow-7.2.0-cp38-cp38-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/davis/anaconda3/lib/python3.8/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: future in /home/davis/.local/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.18.0-py3-none-any.whl size=1656446 sha256=644fc3bd1b144bfcc91eb2f9dc7399f9ea938c0a9053ef2f4bd8d448d3763e94\n",
      "  Stored in directory: /home/davis/.cache/pip/wheels/d8/e7/68/a3f0f1b5831c9321d7523f6fd4e0d3f83f2705a1cbd5daaa79\n",
      "Successfully built gym\n",
      "Installing collected packages: pyglet, Pillow, gym\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.0.1\n",
      "    Uninstalling Pillow-8.0.1:\n",
      "      Successfully uninstalled Pillow-8.0.1\n",
      "Successfully installed Pillow-7.2.0 gym-0.18.0 pyglet-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env #New versions keep getting released; if -v3 doesn't work, try -v2 or -v4\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R, G, B and Y are pickup or dropoff locations.\n",
    "- The blue letter indicates where we need to pick someone up from\n",
    "- the mageneta letter indicates where that passanger wants to go to\n",
    "- The solid lines represent walls that taxi cannot cross\n",
    "- The filled rectangle represents the taxi itself. It's yellow when empty, green when carrying a passanger.\n",
    "\n",
    "The world which we've called the streets is a 5x5 grid. The state of this world at any time can be defined by:\n",
    "\n",
    "- Where the taxi is (one of 25 locations)\n",
    "- What the current destination is (4 possibilities)\n",
    "- Where the passanger is (5 possibilities: at one of the destinations or inside the taxi)\n",
    "\n",
    "So there are a total of 25 x 4 x 5 = 500 possible states that describe our world.\n",
    "\n",
    "For each state, there are six possible actions:\n",
    "    \n",
    "- Move Souh, East, North or West\n",
    "- Pick up a passanger\n",
    "- Drop off a passanger\n",
    "\n",
    "Q-learning will take place using the following rewards and penalties at each state:\n",
    "    \n",
    "    - A successfull drop-off yields +20 points\n",
    "    - Every time step taken while driging a passanger yields a -1 point penalty\n",
    "    - Picking up or dropping off at an illegal location yields a -10 point penalty\n",
    "    \n",
    "    Moving across a wall just isn't allowed at all.\n",
    "    \n",
    "    Let's define an initial state, with the taxi at location (2,3), the passanger at pickup location 2, and the destination at location 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = streets.encode(2, 3, 2, 0)\n",
    "streets.s = initial_state\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the reward table for this initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 368, -1, False)],\n",
       " 1: [(1.0, 168, -1, False)],\n",
       " 2: [(1.0, 288, -1, False)],\n",
       " 3: [(1.0, 248, -1, False)],\n",
       " 4: [(1.0, 268, -10, False)],\n",
       " 5: [(1.0, 268, -10, False)]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets.P[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these rows - each is a potential action at this state. The 4 values in each row are the probability assigned to that action, the next state that results from that action, the reward for tthat action, and whether that action indicates a successfull dropoff took place.\n",
    "\n",
    "So, lets do it. First we need to train our model. At a high level, we'll train over 10,000 simulated taxi runs. For each run, we'll step trough time with a 10% chance at each step of making a random, exploratory step instead of using the learned Q values to guide our actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.6\n",
    "exploration = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        random_value = random.uniform(0, 1)\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Explore a random action\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Use the action with the highest q-value\n",
    "            \n",
    "        next_state, reward, done, info = streets.step(action)\n",
    "        \n",
    "        prev_q = q_table[state, action]\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table[state, action] = new_q\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a table of Q-values that can be quickly used to determine the optimal next step for any given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4145798 , -2.4146969 , -2.40612615, -2.3639511 , -7.31385793,\n",
       "       -8.40116511])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest q-value here corresponds to the action \"go west\" which makes sense -that's the most direct route toward our destination from that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number 10 Step 9\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "for tripnum in range(1, 11):\n",
    "    state = streets.reset()\n",
    "   \n",
    "    done = False\n",
    "    trip_length = 0\n",
    "    \n",
    "    while not done and trip_length < 25:\n",
    "        action = np.argmax(q_table[state])\n",
    "        next_state, reward, done, info = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render(mode='ansi'))\n",
    "        sleep(.5)\n",
    "        state = next_state\n",
    "        trip_length += 1\n",
    "        \n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
